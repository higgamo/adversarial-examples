{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing\n",
    "\n",
    "Printing is done by mostly two line statements.\n",
    "1. One statement print all the arrays of accuracy and loss step by step\n",
    "    `tf.logging.set_verbosity(tf.logging.INFO)`\n",
    "2. The other prints the final accuracy, loss and global step after the end of the step size.\n",
    "    `print(eval_results)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Printing \n",
    "\n",
    "1. To stop the first print statement tf.logging must be changed. The best solution is to set it to ERROR so that error message will print if there is a issue, but all the other info isnt printed.\n",
    "    `tf.logging.set_verbosity(tf.logging.ERROR)`\n",
    "2. The second statement can be removed to stop its printing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n",
    "\n",
    "TensorFlow API called Estimators allows saving setting the directory. `model_dir=\"/home/directoryofyourchoice`\n",
    "it can be saved to a temp folder as well if you do not wish to keep a model after restarting your pc.\n",
    "\n",
    "A model is save in two parts. `graph.ptxt` , `model.ckpt-####` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n",
    "\n",
    "Loading a model can be done in two ways.\n",
    "1. First loading is done automatically by the Estimator. If it detects a `graph.ptxt` and `model.ckpt-####` in the directory it will start training the model at the step it ended at. **Warning!!!** Estimator will automatically load the model in the directory even if it was trained with a different Optimizer and setting.\n",
    "\n",
    "2. Second loading can be done by using restore fuctions build into the tensorflow Api. First the by calling `tf.train.import_meta_graph(/model.ckpt-#####.meta')` with the director to the model. neckpt meta file. Next call the restore() fuction with the directory of the `model.ckpt-####` to load the restore parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with tf.Session() as sess:\n",
    "  new_saver = tf.train.import_meta_graph('/home/higgamo/ten/model3/model.ckpt-2040.meta')\n",
    "  new_saver.restore(sess, \"/home/higgamo/ten/model3/model.ckpt-2040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Samples\n",
    "\n",
    "1. **Fast gradient sign method**- use gradient sign as noise, otherwise use gradient values directly. Empirically gradient sign works better.\n",
    "2. **Fast Gradient Method with Target** - The only difference from FGM is that this is a targeted attack, i.e., a desired target can be provided.\n",
    "3. **Jacobian-based Saliency Map Approach (JSMA)** - it denotes the maximum percentage distortion allowed\n",
    "4. DeepFool\n",
    "6. CW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. plot 3 curves in same chart. then a graph for each one sperate. for thrusday redo labels for plot. method to do so is in slack\n",
    "2. Get adversarial exmaples working (tuesday)\n",
    "3. Walk through on how to make our work for adversrial smaples \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ravi_project]",
   "language": "python",
   "name": "conda-env-ravi_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
